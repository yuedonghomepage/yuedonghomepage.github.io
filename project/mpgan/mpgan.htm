<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="content-type" />
	<title>Synthesizing 3D Shapes from Silhouette Image Collections using Multi-Projection Generative Adversarial Networks</title>
	<link rel="stylesheet" type="text/css" href="../../main.css" media="screen, print" /> 
</head>
<body class="PageContainer">
<div class="PaperPage">
	<div class="PublishInfo">
			Published in
			<span class="BookTitle">IEEE International Conference on Computer Vision and Pattern Recognition, June 2019</span>
	</div>
	<div class="TitleBar">
	<h1>Synthesizing 3D Shapes from Silhouette Image Collections using Multi-Projection Generative Adversarial Networks</h1>
	</div>
	<div class="AuthorBar">
	<ul class="AuthorList">
			<li>
				<span class="Author"><a href="http://home.ustc.edu.cn/~pableeto/" target="_blank">
				Xiao Li</a><sup>1,2</sup></span>
			</li>
			<li>
				<span class="Author"><a href="http://yuedong.shading.me/" target="_blank">
				Yue Dong</a><sup>2</sup>
			</li>
			<li>
				<span class="Author"><a href="http://www.cs.wm.edu/~ppeers/" target="_blank">
				Pieter Peers</a><sup>3</sup></span>
			</li>
			<li>
				<span class="Author"><a href="http://research.microsoft.com/users/xtong/xtong.html" target="_blank">
				Xin Tong</a><sup>2</sup></span>
			</li>
		</ul>

		<ul class="AuthorList">
			<li>
				<span class="Affiliation"><sup>1</sup>University of Science and Technology of China</span>
			</li>
			<li>
				<span class="Affiliation"><sup>2</sup>Microsof Research Asia</span>
			</li>
			<li>
				<span class="Affiliation"><sup>3</sup> College of William & Mary</span>
			</li>
		</ul>   
	</div>
	
	<div class="TeaserBar">
	<img src="teaser.png" alt="rendering resutls" class="PaperFigure" />
	</div>
    <p class="FigureDescription">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Results generated by VP-MP-GAN trained on the bird
dataset</p>
  	       
	<div class="AbstractBar">
	<h2 class="PaperSectionTitle">Abstract</h2>
    <p class="Abstract">
 We present a new weakly supervised learning-based method for generating novel category-specific 3D shapes from unoccluded image collections. Our method is weakly supervised and only requires silhouette annotations from unoccluded, category-specific objects. Our method does not require access to the object's 3D shape, multiple observations per object from different views, intra-image pixel-correspondences, or any view annotations. Key to our method is a novel multi-projection generative adversarial network (MP-GAN) that trains a 3D shape generator to be consistent with multiple 2D projections of the 3D shapes, and without direct access to these 3D shapes. This is achieved through multiple discriminators that encode the distribution of 2D projections of the 3D shapes seen from a different views. Additionally, to determine the view information for each silhouette image, we also train a view prediction network on visualizations of 3D shapes synthesized by the generator. We iteratively alternate between training the generator and training the view prediction network. We validate our multi-projection GAN on both synthetic and real image datasets. Furthermore, we also show that multi-projection GANs can aid in learning other high-dimensional distributions from lower dimensional training datasets, such as material-class specific spatially varying reflectance properties from images.

 </p>
   </div>

    
    <table class="TwoColumnPaper">
      <tr>
        <td>
		
   	<h2 class="PaperSectionTitle">Keywords</h2>
    <p class="Keywords">GAN, Generative Adversarial Networks, Multi-Projection</p>

    <h2 class="PaperSectionTitle">Paper and video</h2>
    
    <div class="PaperDownloadList">
        <ul>
			<a href="mpgan.pdf">
            <li>
                <span class="FileTitle">Paper</span>
                <span class="FileDesc">.pdf | 6.2 MB</span>             
            </li>
			</a>
        </ul>
    </div>
    <h2 class="PaperSectionTitle">Trained model and code</h2>

    <div class="PaperDownloadList">
        <ul>
			<a href="https://github.com/msraig/mp_gan">
            <li>
                <span class="FileTitle">GitHub Repo</span>
                <span class="FileDesc">Code and model</span>             
            </li>
			</a>
        </ul>
    </div>

    </td>
    <td>
	<h2 class="PaperSectionTitle">Acknowledgements</h2>
    <p class="Acknowledgements">We would like to thank the reviewers for their constructive feedback. We also thank Baining
Guo for discussions and suggestions. Pieter Peers was partially supported by NSF grant IIS-1350323 and gifts from
Google, Activision, and Nvidia.
</p>



	</td>
	</tr>
	</table>

</div>
</body>
</html>
