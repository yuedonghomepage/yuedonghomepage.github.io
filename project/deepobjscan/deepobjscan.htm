<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="content-type" />
	<title>Deep Inverse Rendering for Practical
                Object Appearance Scan with Uncalibrated Illumination</title>
	<link rel="stylesheet" type="text/css" href="../../main.css" media="screen, print" /> 
</head>
<body class="PageContainer">
<div class="PaperPage">
	<div class="PublishInfo">
			Published in
			<span class="BookTitle">CGI 2020: Advances in Computer Graphics</span>
	</div>
	<div class="TitleBar">
	<h1>Deep Inverse Rendering for Practical
                Object Appearance Scan with Uncalibrated Illumination</h1>
	</div>
	<div class="AuthorBar">
	<ul class="AuthorList">
			<li>
				<span class="Author">
				Jianzhao Zhang<sup>1,3</sup></span>
			</li>
			<li>
				<span class="Author">
				Guojun Chen</a><sup>2</sup></span>
			</li>
			<li>
				<span class="Author">
				Yue Dong<sup>2</sup></span>
			</li>
			<li>
				<span class="Author">
				Jian Shi</a><sup>4</sup></span>
			</li>
			<li>
				<span class="Author">
				Bob Zhang</a><sup>5</sup></span>
			</li>
			<li>
				<span class="Author">
				Enhua Wu</a><sup>1,5</sup></span>
			</li>
		</ul>

		<ul class="AuthorList">
			<li>
				<span class="Affiliation"><sup>1</sup>Institute of Software, Chinese Academy of Sciences, Beijing</span>
			</li>
			<li>
				<span class="Affiliation"><sup>2</sup>Microsof Research Asia</span>
			</li>
			<li>
				<span class="Affiliation"><sup>3</sup>University of Chinese Academy of Sciences</span>
			</li>
			<li>
				<span class="Affiliation"><sup>4</sup>Institute of Automation, Chinese Academy of Sciences</span>
			</li>
			<li>
				<span class="Affiliation"><sup>4</sup>University of Macau</span>
			</li>
		</ul>   
	</div>
	
	<div class="AbstractBar">
	<h2 class="PaperSectionTitle">Abstract</h2>
    <p class="Abstract">
In this paper, we propose a practical method to estimate
object appearance from an arbitrary number of images. We use a moving flashlight as light source, and encode surface reflectance properties
in a pre-learned embedded latent space. Such lighting and appearance
model combination enables our method to effectively narrow the solution
space. Uncalibrated illumination requirement extremely simplifies our
setup and affords it unnecessary to accurately locate light positions in
advance. Moreover, our method automatically selects key frames before
appearance estimation, which largely reduces calculation cost. Both synthetic and real experiments demonstrate that our method can recover
object appearance accurately and conveniently.

 </p>
   </div>

    
    <table class="TwoColumnPaper">
      <tr>
        <td>

   	<h2 class="PaperSectionTitle">Keywords</h2>
    <p class="Keywords">Appearance modeling, Inverse rendering</p>

    <h2 class="PaperSectionTitle">Paper and video</h2>
    
    <div class="PaperDownloadList">
        <ul>
			<a href="deepobjscan.pdf">
            <li>
                <span class="FileTitle">Paper</span>
                <span class="FileDesc">.pdf | 23.6 MB</span>             
            </li>
			</a>
        </ul>
    </div>

    </td>
    <td>
	<h2 class="PaperSectionTitle">Acknowledgements</h2>
    <p class="Acknowledgements">This work is partially supported by the National Natural Science
Foundation of China (Nos. 61632003) and is also funded in part by the University of
Macau under Grant MYRG2019-00006-FST.
</p>



	</td>
	</tr>
	</table>

</div>
</body>
</html>
